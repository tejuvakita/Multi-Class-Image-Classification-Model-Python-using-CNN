{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9680899-1274-40f1-b16f-b40a9c0ba75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/poonam/.local/lib/python3.6/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88a50577-5eb6-4421-aec6-b1f4db1878d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['driving license','social security','Others']\n",
    "img_size = 224\n",
    "def get_data(data_dir):\n",
    "    \"\"\"\n",
    "    data directory where all class will have folders and all the images will be in that directory\n",
    "    \"\"\"\n",
    "    data = [] \n",
    "    for each_label in label: \n",
    "        #print(each_label)\n",
    "        path = os.path.join(data_dir, each_label)\n",
    "        #print(path)\n",
    "        class_num = label.index(each_label)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                #convert BGR to RGB format\n",
    "                img_arr = cv2.imread(os.path.join(path, img))[...,::-1] \n",
    "                # Reshaping images to preferred size\n",
    "                resized_arr = cv2.resize(img_arr, (img_size, img_size)) \n",
    "                data.append([resized_arr, class_num])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45fe6ed6-d150-4d57-b7b9-28777e5cd972",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = get_data('./Training data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a9f509d-9039-4880-8267-373b87140030",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/poonam/.local/lib/python3.6/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f999b3b9f60>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l = []\n",
    "for i in train:\n",
    "    if(i[1] == 0):\n",
    "        l.append(\"driving license\")\n",
    "    elif(i[1]==1):\n",
    "        l.append(\"social security\")\n",
    "    else:\n",
    "        l.append(\"Others\")\n",
    "sns.set_style('darkgrid')\n",
    "sns.countplot(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f908f982-59d7-47a5-8cae-7c3bed8bdd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make numpy array of xtrain and y train,normalize it,and reshape to 224*224\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_val = []\n",
    "y_val = []\n",
    "\n",
    "for feature, label in train:\n",
    "    x_train.append(feature)\n",
    "    y_train.append(label)\n",
    "\n",
    "# Normalize the data\n",
    "x_train = np.array(x_train) / 255\n",
    "x_val = np.array(x_val) / 255\n",
    "\n",
    "x_train.reshape(-1, img_size, img_size, 1)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_val.reshape(-1, img_size, img_size, 1)\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ddcb1e6-652c-4840-b1da-231f0de9ec53",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Image data generator with given parameters \n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.2, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip = True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f38b3bd5-4c79-43b3-9aa5-1e51d25a1f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 112, 112, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 56, 56, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1605760   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 1,644,035\n",
      "Trainable params: 1,644,035\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### adding sequential model ,add a bunch of conv,maxpool,dropout ,flatten it and then eventually add a dense of 3 for all 3 classes.\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32,3,padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation=\"relu\"))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e83b15e-cbb1-4a19-a865-147841121bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compilation of model with adam optimizer of 0.000001\n",
    "opt = Adam(lr=0.000001)\n",
    "model.compile(optimizer = opt , loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) , metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bec3bcb7-0c45-4c93-bc7e-00e7a9a321f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "19/19 [==============================] - 39s 2s/step - loss: 1.1004 - accuracy: 0.3283\n",
      "Epoch 2/200\n",
      "19/19 [==============================] - 38s 2s/step - loss: 1.0982 - accuracy: 0.3400\n",
      "Epoch 3/200\n",
      "19/19 [==============================] - 15s 764ms/step - loss: 1.0984 - accuracy: 0.3517\n",
      "Epoch 4/200\n",
      "19/19 [==============================] - 12s 642ms/step - loss: 1.0978 - accuracy: 0.3600\n",
      "Epoch 5/200\n",
      "19/19 [==============================] - 12s 646ms/step - loss: 1.0985 - accuracy: 0.3300\n",
      "Epoch 6/200\n",
      "19/19 [==============================] - 12s 651ms/step - loss: 1.0970 - accuracy: 0.3583\n",
      "Epoch 7/200\n",
      "19/19 [==============================] - 13s 662ms/step - loss: 1.0991 - accuracy: 0.3350\n",
      "Epoch 8/200\n",
      "19/19 [==============================] - 13s 694ms/step - loss: 1.0964 - accuracy: 0.3817\n",
      "Epoch 9/200\n",
      "19/19 [==============================] - 13s 665ms/step - loss: 1.0964 - accuracy: 0.3817\n",
      "Epoch 10/200\n",
      "19/19 [==============================] - 12s 655ms/step - loss: 1.0965 - accuracy: 0.3683\n",
      "Epoch 11/200\n",
      "19/19 [==============================] - 12s 653ms/step - loss: 1.0974 - accuracy: 0.3483\n",
      "Epoch 12/200\n",
      "19/19 [==============================] - 13s 693ms/step - loss: 1.0959 - accuracy: 0.3783\n",
      "Epoch 13/200\n",
      "19/19 [==============================] - 13s 661ms/step - loss: 1.0942 - accuracy: 0.4167\n",
      "Epoch 14/200\n",
      "19/19 [==============================] - 13s 668ms/step - loss: 1.0951 - accuracy: 0.4000\n",
      "Epoch 15/200\n",
      "19/19 [==============================] - 13s 658ms/step - loss: 1.0945 - accuracy: 0.3950\n",
      "Epoch 16/200\n",
      "19/19 [==============================] - 13s 667ms/step - loss: 1.0945 - accuracy: 0.3883\n",
      "Epoch 17/200\n",
      "19/19 [==============================] - 13s 687ms/step - loss: 1.0935 - accuracy: 0.4017\n",
      "Epoch 18/200\n",
      "19/19 [==============================] - 13s 667ms/step - loss: 1.0931 - accuracy: 0.3950\n",
      "Epoch 19/200\n",
      "19/19 [==============================] - 13s 671ms/step - loss: 1.0948 - accuracy: 0.3983\n",
      "Epoch 20/200\n",
      "19/19 [==============================] - 13s 662ms/step - loss: 1.0951 - accuracy: 0.3733\n",
      "Epoch 21/200\n",
      "19/19 [==============================] - 13s 691ms/step - loss: 1.0920 - accuracy: 0.4100\n",
      "Epoch 22/200\n",
      "19/19 [==============================] - 12s 653ms/step - loss: 1.0941 - accuracy: 0.4133\n",
      "Epoch 23/200\n",
      "19/19 [==============================] - 13s 660ms/step - loss: 1.0930 - accuracy: 0.3967\n",
      "Epoch 24/200\n",
      "19/19 [==============================] - 12s 650ms/step - loss: 1.0937 - accuracy: 0.3950\n",
      "Epoch 25/200\n",
      "19/19 [==============================] - 12s 657ms/step - loss: 1.0918 - accuracy: 0.4517\n",
      "Epoch 26/200\n",
      "19/19 [==============================] - 12s 651ms/step - loss: 1.0911 - accuracy: 0.4367\n",
      "Epoch 27/200\n",
      "19/19 [==============================] - 12s 649ms/step - loss: 1.0931 - accuracy: 0.3983\n",
      "Epoch 28/200\n",
      "19/19 [==============================] - 12s 650ms/step - loss: 1.0934 - accuracy: 0.4233\n",
      "Epoch 29/200\n",
      "19/19 [==============================] - 12s 654ms/step - loss: 1.0911 - accuracy: 0.4100\n",
      "Epoch 30/200\n",
      "19/19 [==============================] - 13s 682ms/step - loss: 1.0916 - accuracy: 0.4417\n",
      "Epoch 31/200\n",
      "19/19 [==============================] - 13s 661ms/step - loss: 1.0917 - accuracy: 0.4200\n",
      "Epoch 32/200\n",
      "19/19 [==============================] - 12s 648ms/step - loss: 1.0918 - accuracy: 0.4133\n",
      "Epoch 33/200\n",
      "19/19 [==============================] - 12s 655ms/step - loss: 1.0881 - accuracy: 0.4617\n",
      "Epoch 34/200\n",
      "19/19 [==============================] - 12s 657ms/step - loss: 1.0898 - accuracy: 0.4617\n",
      "Epoch 35/200\n",
      "19/19 [==============================] - 14s 716ms/step - loss: 1.0889 - accuracy: 0.4600\n",
      "Epoch 36/200\n",
      "19/19 [==============================] - 13s 659ms/step - loss: 1.0875 - accuracy: 0.4767\n",
      "Epoch 37/200\n",
      "19/19 [==============================] - 12s 648ms/step - loss: 1.0903 - accuracy: 0.4367\n",
      "Epoch 38/200\n",
      "19/19 [==============================] - 13s 682ms/step - loss: 1.0880 - accuracy: 0.4717\n",
      "Epoch 39/200\n",
      "19/19 [==============================] - 13s 662ms/step - loss: 1.0881 - accuracy: 0.4567\n",
      "Epoch 40/200\n",
      "19/19 [==============================] - 13s 659ms/step - loss: 1.0885 - accuracy: 0.4600\n",
      "Epoch 41/200\n",
      "19/19 [==============================] - 12s 657ms/step - loss: 1.0866 - accuracy: 0.4867\n",
      "Epoch 42/200\n",
      "19/19 [==============================] - 13s 659ms/step - loss: 1.0848 - accuracy: 0.5000\n",
      "Epoch 43/200\n",
      "19/19 [==============================] - 13s 663ms/step - loss: 1.0841 - accuracy: 0.4967\n",
      "Epoch 44/200\n",
      "19/19 [==============================] - 13s 696ms/step - loss: 1.0869 - accuracy: 0.4483\n",
      "Epoch 45/200\n",
      "19/19 [==============================] - 13s 668ms/step - loss: 1.0855 - accuracy: 0.4967\n",
      "Epoch 46/200\n",
      "19/19 [==============================] - 12s 657ms/step - loss: 1.0837 - accuracy: 0.5000\n",
      "Epoch 47/200\n",
      "19/19 [==============================] - 13s 659ms/step - loss: 1.0831 - accuracy: 0.5083\n",
      "Epoch 48/200\n",
      "19/19 [==============================] - 13s 684ms/step - loss: 1.0810 - accuracy: 0.5350\n",
      "Epoch 49/200\n",
      "19/19 [==============================] - 13s 659ms/step - loss: 1.0827 - accuracy: 0.5183\n",
      "Epoch 50/200\n",
      "19/19 [==============================] - 13s 661ms/step - loss: 1.0813 - accuracy: 0.5017\n",
      "Epoch 51/200\n",
      "19/19 [==============================] - 13s 662ms/step - loss: 1.0815 - accuracy: 0.5383\n",
      "Epoch 52/200\n",
      "19/19 [==============================] - 13s 671ms/step - loss: 1.0792 - accuracy: 0.5283\n",
      "Epoch 53/200\n",
      "19/19 [==============================] - 13s 698ms/step - loss: 1.0788 - accuracy: 0.5583\n",
      "Epoch 54/200\n",
      "19/19 [==============================] - 13s 663ms/step - loss: 1.0790 - accuracy: 0.5533\n",
      "Epoch 55/200\n",
      "19/19 [==============================] - 12s 651ms/step - loss: 1.0785 - accuracy: 0.5367\n",
      "Epoch 56/200\n",
      "19/19 [==============================] - 12s 653ms/step - loss: 1.0782 - accuracy: 0.5683\n",
      "Epoch 57/200\n",
      "19/19 [==============================] - 13s 663ms/step - loss: 1.0769 - accuracy: 0.5367\n",
      "Epoch 58/200\n",
      "19/19 [==============================] - 13s 660ms/step - loss: 1.0751 - accuracy: 0.5700\n",
      "Epoch 59/200\n",
      "19/19 [==============================] - 13s 660ms/step - loss: 1.0743 - accuracy: 0.5567\n",
      "Epoch 60/200\n",
      "19/19 [==============================] - 12s 658ms/step - loss: 1.0741 - accuracy: 0.5650\n",
      "Epoch 61/200\n",
      "19/19 [==============================] - 13s 664ms/step - loss: 1.0728 - accuracy: 0.5950\n",
      "Epoch 62/200\n",
      "19/19 [==============================] - 13s 699ms/step - loss: 1.0727 - accuracy: 0.6017\n",
      "Epoch 63/200\n",
      "19/19 [==============================] - 12s 656ms/step - loss: 1.0696 - accuracy: 0.5767\n",
      "Epoch 64/200\n",
      "19/19 [==============================] - 12s 655ms/step - loss: 1.0724 - accuracy: 0.5900\n",
      "Epoch 65/200\n",
      "19/19 [==============================] - 12s 657ms/step - loss: 1.0688 - accuracy: 0.6100\n",
      "Epoch 66/200\n",
      "19/19 [==============================] - 13s 702ms/step - loss: 1.0698 - accuracy: 0.5817\n",
      "Epoch 67/200\n",
      "19/19 [==============================] - 13s 661ms/step - loss: 1.0680 - accuracy: 0.5850\n",
      "Epoch 68/200\n",
      "19/19 [==============================] - 13s 662ms/step - loss: 1.0681 - accuracy: 0.6050\n",
      "Epoch 69/200\n",
      "19/19 [==============================] - 12s 655ms/step - loss: 1.0635 - accuracy: 0.6250\n",
      "Epoch 70/200\n",
      "19/19 [==============================] - 13s 660ms/step - loss: 1.0594 - accuracy: 0.6433\n",
      "Epoch 71/200\n",
      "19/19 [==============================] - 13s 658ms/step - loss: 1.0603 - accuracy: 0.6433\n",
      "Epoch 72/200\n",
      "19/19 [==============================] - 13s 658ms/step - loss: 1.0603 - accuracy: 0.6067\n",
      "Epoch 73/200\n",
      "19/19 [==============================] - 13s 661ms/step - loss: 1.0609 - accuracy: 0.6250\n",
      "Epoch 74/200\n",
      "19/19 [==============================] - 13s 668ms/step - loss: 1.0573 - accuracy: 0.6567\n",
      "Epoch 75/200\n",
      "19/19 [==============================] - 14s 719ms/step - loss: 1.0554 - accuracy: 0.6400\n",
      "Epoch 76/200\n",
      "19/19 [==============================] - 13s 669ms/step - loss: 1.0541 - accuracy: 0.6333\n",
      "Epoch 77/200\n",
      "19/19 [==============================] - 13s 690ms/step - loss: 1.0542 - accuracy: 0.6467\n",
      "Epoch 78/200\n",
      "19/19 [==============================] - 13s 669ms/step - loss: 1.0531 - accuracy: 0.6333\n",
      "Epoch 79/200\n",
      "19/19 [==============================] - 13s 679ms/step - loss: 1.0502 - accuracy: 0.6467\n",
      "Epoch 80/200\n",
      "19/19 [==============================] - 13s 668ms/step - loss: 1.0454 - accuracy: 0.6283\n",
      "Epoch 81/200\n",
      "19/19 [==============================] - 12s 652ms/step - loss: 1.0485 - accuracy: 0.6183\n",
      "Epoch 82/200\n",
      "19/19 [==============================] - 12s 655ms/step - loss: 1.0450 - accuracy: 0.6633\n",
      "Epoch 83/200\n",
      "19/19 [==============================] - 13s 658ms/step - loss: 1.0479 - accuracy: 0.6567\n",
      "Epoch 84/200\n",
      "19/19 [==============================] - 13s 703ms/step - loss: 1.0419 - accuracy: 0.6433\n",
      "Epoch 85/200\n",
      "19/19 [==============================] - 12s 657ms/step - loss: 1.0397 - accuracy: 0.6667\n",
      "Epoch 86/200\n",
      "19/19 [==============================] - 12s 652ms/step - loss: 1.0409 - accuracy: 0.6617\n",
      "Epoch 87/200\n",
      "19/19 [==============================] - 12s 653ms/step - loss: 1.0342 - accuracy: 0.7033\n",
      "Epoch 88/200\n",
      "19/19 [==============================] - 13s 662ms/step - loss: 1.0351 - accuracy: 0.6733\n",
      "Epoch 89/200\n",
      "19/19 [==============================] - 12s 657ms/step - loss: 1.0319 - accuracy: 0.6950\n",
      "Epoch 90/200\n",
      "19/19 [==============================] - 13s 660ms/step - loss: 1.0337 - accuracy: 0.6633\n",
      "Epoch 91/200\n",
      "19/19 [==============================] - 13s 660ms/step - loss: 1.0315 - accuracy: 0.6583\n",
      "Epoch 92/200\n",
      "19/19 [==============================] - 12s 656ms/step - loss: 1.0258 - accuracy: 0.6933\n",
      "Epoch 93/200\n",
      "19/19 [==============================] - 14s 722ms/step - loss: 1.0268 - accuracy: 0.6817\n",
      "Epoch 94/200\n",
      "19/19 [==============================] - 13s 663ms/step - loss: 1.0265 - accuracy: 0.6983\n",
      "Epoch 95/200\n",
      "19/19 [==============================] - 13s 659ms/step - loss: 1.0235 - accuracy: 0.6900\n",
      "Epoch 96/200\n",
      "19/19 [==============================] - 13s 662ms/step - loss: 1.0155 - accuracy: 0.7333\n",
      "Epoch 97/200\n",
      "19/19 [==============================] - 13s 681ms/step - loss: 1.0199 - accuracy: 0.6950\n",
      "Epoch 98/200\n",
      "19/19 [==============================] - 13s 668ms/step - loss: 1.0169 - accuracy: 0.6967\n",
      "Epoch 99/200\n",
      "19/19 [==============================] - 13s 658ms/step - loss: 1.0156 - accuracy: 0.7017\n",
      "Epoch 100/200\n",
      "19/19 [==============================] - 13s 658ms/step - loss: 1.0133 - accuracy: 0.7100\n",
      "Epoch 101/200\n",
      "19/19 [==============================] - 13s 667ms/step - loss: 1.0104 - accuracy: 0.7200\n",
      "Epoch 102/200\n",
      "19/19 [==============================] - 13s 665ms/step - loss: 1.0092 - accuracy: 0.7183\n",
      "Epoch 103/200\n",
      "19/19 [==============================] - 12s 657ms/step - loss: 1.0104 - accuracy: 0.7200\n",
      "Epoch 104/200\n",
      "19/19 [==============================] - 13s 660ms/step - loss: 1.0024 - accuracy: 0.7400\n",
      "Epoch 105/200\n",
      "19/19 [==============================] - 12s 649ms/step - loss: 0.9979 - accuracy: 0.7317\n",
      "Epoch 106/200\n",
      "19/19 [==============================] - 13s 709ms/step - loss: 0.9975 - accuracy: 0.7217\n",
      "Epoch 107/200\n",
      "19/19 [==============================] - 13s 677ms/step - loss: 0.9977 - accuracy: 0.7267\n",
      "Epoch 108/200\n",
      "19/19 [==============================] - 13s 660ms/step - loss: 0.9945 - accuracy: 0.7400\n",
      "Epoch 109/200\n",
      "19/19 [==============================] - 13s 659ms/step - loss: 0.9908 - accuracy: 0.7350\n",
      "Epoch 110/200\n",
      "19/19 [==============================] - 13s 664ms/step - loss: 0.9898 - accuracy: 0.7500\n",
      "Epoch 111/200\n",
      "19/19 [==============================] - 13s 693ms/step - loss: 0.9904 - accuracy: 0.7217\n",
      "Epoch 112/200\n",
      "19/19 [==============================] - 12s 652ms/step - loss: 0.9870 - accuracy: 0.7200\n",
      "Epoch 113/200\n",
      "19/19 [==============================] - 13s 663ms/step - loss: 0.9835 - accuracy: 0.7450\n",
      "Epoch 114/200\n",
      "19/19 [==============================] - 13s 661ms/step - loss: 0.9831 - accuracy: 0.7400\n",
      "Epoch 115/200\n",
      "19/19 [==============================] - 13s 665ms/step - loss: 0.9766 - accuracy: 0.7450\n",
      "Epoch 116/200\n",
      "19/19 [==============================] - 12s 656ms/step - loss: 0.9760 - accuracy: 0.7700\n",
      "Epoch 117/200\n",
      "19/19 [==============================] - 12s 656ms/step - loss: 0.9757 - accuracy: 0.7433\n",
      "Epoch 118/200\n",
      "19/19 [==============================] - 12s 657ms/step - loss: 0.9706 - accuracy: 0.7483\n",
      "Epoch 119/200\n",
      "19/19 [==============================] - 13s 673ms/step - loss: 0.9682 - accuracy: 0.7550\n",
      "Epoch 120/200\n",
      "19/19 [==============================] - 14s 719ms/step - loss: 0.9668 - accuracy: 0.7683\n",
      "Epoch 121/200\n",
      "19/19 [==============================] - 13s 669ms/step - loss: 0.9654 - accuracy: 0.7667\n",
      "Epoch 122/200\n",
      "19/19 [==============================] - 13s 662ms/step - loss: 0.9632 - accuracy: 0.7550\n",
      "Epoch 123/200\n",
      "19/19 [==============================] - 13s 658ms/step - loss: 0.9570 - accuracy: 0.7833\n",
      "Epoch 124/200\n",
      "19/19 [==============================] - 13s 690ms/step - loss: 0.9546 - accuracy: 0.7617\n",
      "Epoch 125/200\n",
      "19/19 [==============================] - 13s 659ms/step - loss: 0.9540 - accuracy: 0.7750\n",
      "Epoch 126/200\n",
      "19/19 [==============================] - 12s 656ms/step - loss: 0.9553 - accuracy: 0.7483\n",
      "Epoch 127/200\n",
      "19/19 [==============================] - 13s 662ms/step - loss: 0.9496 - accuracy: 0.7833\n",
      "Epoch 128/200\n",
      "19/19 [==============================] - 13s 662ms/step - loss: 0.9450 - accuracy: 0.7567\n",
      "Epoch 129/200\n",
      "19/19 [==============================] - 13s 699ms/step - loss: 0.9493 - accuracy: 0.7750\n",
      "Epoch 130/200\n",
      "19/19 [==============================] - 12s 656ms/step - loss: 0.9482 - accuracy: 0.7550\n",
      "Epoch 131/200\n",
      "19/19 [==============================] - 12s 658ms/step - loss: 0.9407 - accuracy: 0.7817\n",
      "Epoch 132/200\n",
      "19/19 [==============================] - 13s 661ms/step - loss: 0.9435 - accuracy: 0.7600\n",
      "Epoch 133/200\n",
      "19/19 [==============================] - 13s 699ms/step - loss: 0.9381 - accuracy: 0.7867\n",
      "Epoch 134/200\n",
      "19/19 [==============================] - 13s 663ms/step - loss: 0.9337 - accuracy: 0.7700\n",
      "Epoch 135/200\n",
      "19/19 [==============================] - 12s 656ms/step - loss: 0.9331 - accuracy: 0.7683\n",
      "Epoch 136/200\n",
      "19/19 [==============================] - 12s 655ms/step - loss: 0.9319 - accuracy: 0.7817\n",
      "Epoch 137/200\n",
      "19/19 [==============================] - 13s 668ms/step - loss: 0.9265 - accuracy: 0.7767\n",
      "Epoch 138/200\n",
      "19/19 [==============================] - 13s 691ms/step - loss: 0.9307 - accuracy: 0.7617\n",
      "Epoch 139/200\n",
      "19/19 [==============================] - 13s 660ms/step - loss: 0.9239 - accuracy: 0.7817\n",
      "Epoch 140/200\n",
      "19/19 [==============================] - 12s 653ms/step - loss: 0.9205 - accuracy: 0.7717\n",
      "Epoch 141/200\n",
      "19/19 [==============================] - 12s 656ms/step - loss: 0.9175 - accuracy: 0.7883\n",
      "Epoch 142/200\n",
      "19/19 [==============================] - 13s 664ms/step - loss: 0.9164 - accuracy: 0.7983\n",
      "Epoch 143/200\n",
      "19/19 [==============================] - 13s 660ms/step - loss: 0.9182 - accuracy: 0.7817\n",
      "Epoch 144/200\n",
      "19/19 [==============================] - 13s 663ms/step - loss: 0.9144 - accuracy: 0.7817\n",
      "Epoch 145/200\n",
      "19/19 [==============================] - 13s 661ms/step - loss: 0.9115 - accuracy: 0.7883\n",
      "Epoch 146/200\n",
      "19/19 [==============================] - 13s 670ms/step - loss: 0.9095 - accuracy: 0.7717\n",
      "Epoch 147/200\n",
      "19/19 [==============================] - 13s 710ms/step - loss: 0.9095 - accuracy: 0.7817\n",
      "Epoch 148/200\n",
      "19/19 [==============================] - 13s 665ms/step - loss: 0.9022 - accuracy: 0.7983\n",
      "Epoch 149/200\n",
      "19/19 [==============================] - 13s 658ms/step - loss: 0.9002 - accuracy: 0.7850\n",
      "Epoch 150/200\n",
      "19/19 [==============================] - 12s 657ms/step - loss: 0.9005 - accuracy: 0.7850\n",
      "Epoch 151/200\n",
      "19/19 [==============================] - 13s 703ms/step - loss: 0.9014 - accuracy: 0.7883\n",
      "Epoch 152/200\n",
      "19/19 [==============================] - 13s 664ms/step - loss: 0.8979 - accuracy: 0.7850\n",
      "Epoch 153/200\n",
      "19/19 [==============================] - 13s 661ms/step - loss: 0.8942 - accuracy: 0.7933\n",
      "Epoch 154/200\n",
      "19/19 [==============================] - 13s 660ms/step - loss: 0.8929 - accuracy: 0.7950\n",
      "Epoch 155/200\n",
      "19/19 [==============================] - 13s 660ms/step - loss: 0.8899 - accuracy: 0.8100\n",
      "Epoch 156/200\n",
      "19/19 [==============================] - 12s 656ms/step - loss: 0.8888 - accuracy: 0.8000\n",
      "Epoch 157/200\n",
      "19/19 [==============================] - 12s 658ms/step - loss: 0.8885 - accuracy: 0.7917\n",
      "Epoch 158/200\n",
      "19/19 [==============================] - 13s 658ms/step - loss: 0.8875 - accuracy: 0.7917\n",
      "Epoch 159/200\n",
      "19/19 [==============================] - 12s 658ms/step - loss: 0.8829 - accuracy: 0.8000\n",
      "Epoch 160/200\n",
      "19/19 [==============================] - 14s 716ms/step - loss: 0.8805 - accuracy: 0.7983\n",
      "Epoch 161/200\n",
      "19/19 [==============================] - 13s 660ms/step - loss: 0.8802 - accuracy: 0.8050\n",
      "Epoch 162/200\n",
      "19/19 [==============================] - 13s 662ms/step - loss: 0.8777 - accuracy: 0.8017\n",
      "Epoch 163/200\n",
      "19/19 [==============================] - 13s 658ms/step - loss: 0.8747 - accuracy: 0.7967\n",
      "Epoch 164/200\n",
      "19/19 [==============================] - 13s 678ms/step - loss: 0.8758 - accuracy: 0.7867\n",
      "Epoch 165/200\n",
      "19/19 [==============================] - 13s 686ms/step - loss: 0.8776 - accuracy: 0.7883\n",
      "Epoch 166/200\n",
      "19/19 [==============================] - 12s 657ms/step - loss: 0.8659 - accuracy: 0.8183\n",
      "Epoch 167/200\n",
      "19/19 [==============================] - 12s 655ms/step - loss: 0.8720 - accuracy: 0.8183\n",
      "Epoch 168/200\n",
      "19/19 [==============================] - 13s 662ms/step - loss: 0.8720 - accuracy: 0.8017\n",
      "Epoch 169/200\n",
      "19/19 [==============================] - 13s 668ms/step - loss: 0.8663 - accuracy: 0.8100\n",
      "Epoch 170/200\n",
      "19/19 [==============================] - 13s 664ms/step - loss: 0.8667 - accuracy: 0.8083\n",
      "Epoch 171/200\n",
      "19/19 [==============================] - 13s 659ms/step - loss: 0.8632 - accuracy: 0.8067\n",
      "Epoch 172/200\n",
      "19/19 [==============================] - 13s 660ms/step - loss: 0.8620 - accuracy: 0.8167\n",
      "Epoch 173/200\n",
      "19/19 [==============================] - 13s 677ms/step - loss: 0.8594 - accuracy: 0.8150\n",
      "Epoch 174/200\n",
      "19/19 [==============================] - 13s 674ms/step - loss: 0.8580 - accuracy: 0.8183\n",
      "Epoch 175/200\n",
      "19/19 [==============================] - 12s 657ms/step - loss: 0.8612 - accuracy: 0.7950\n",
      "Epoch 176/200\n",
      "19/19 [==============================] - 12s 652ms/step - loss: 0.8546 - accuracy: 0.8150\n",
      "Epoch 177/200\n",
      "19/19 [==============================] - 12s 657ms/step - loss: 0.8582 - accuracy: 0.8133\n",
      "Epoch 178/200\n",
      "19/19 [==============================] - 14s 719ms/step - loss: 0.8521 - accuracy: 0.7967\n",
      "Epoch 179/200\n",
      "19/19 [==============================] - 13s 668ms/step - loss: 0.8505 - accuracy: 0.8133\n",
      "Epoch 180/200\n",
      "19/19 [==============================] - 13s 663ms/step - loss: 0.8501 - accuracy: 0.8083\n",
      "Epoch 181/200\n",
      "19/19 [==============================] - 13s 659ms/step - loss: 0.8490 - accuracy: 0.8050\n",
      "Epoch 182/200\n",
      "19/19 [==============================] - 13s 680ms/step - loss: 0.8465 - accuracy: 0.8067\n",
      "Epoch 183/200\n",
      "19/19 [==============================] - 13s 674ms/step - loss: 0.8468 - accuracy: 0.8117\n",
      "Epoch 184/200\n",
      "19/19 [==============================] - 13s 660ms/step - loss: 0.8410 - accuracy: 0.8233\n",
      "Epoch 185/200\n",
      "19/19 [==============================] - 13s 662ms/step - loss: 0.8435 - accuracy: 0.8133\n",
      "Epoch 186/200\n",
      "19/19 [==============================] - 13s 662ms/step - loss: 0.8437 - accuracy: 0.8050\n",
      "Epoch 187/200\n",
      "19/19 [==============================] - 13s 674ms/step - loss: 0.8359 - accuracy: 0.8250\n",
      "Epoch 188/200\n",
      "19/19 [==============================] - 12s 657ms/step - loss: 0.8419 - accuracy: 0.8050\n",
      "Epoch 189/200\n",
      "19/19 [==============================] - 12s 654ms/step - loss: 0.8346 - accuracy: 0.8167\n",
      "Epoch 190/200\n",
      "19/19 [==============================] - 12s 657ms/step - loss: 0.8339 - accuracy: 0.8367\n",
      "Epoch 191/200\n",
      "19/19 [==============================] - 13s 704ms/step - loss: 0.8349 - accuracy: 0.8083\n",
      "Epoch 192/200\n",
      "19/19 [==============================] - 13s 668ms/step - loss: 0.8315 - accuracy: 0.8233\n",
      "Epoch 193/200\n",
      "19/19 [==============================] - 13s 679ms/step - loss: 0.8331 - accuracy: 0.8067\n",
      "Epoch 194/200\n",
      "19/19 [==============================] - 13s 664ms/step - loss: 0.8318 - accuracy: 0.8133\n",
      "Epoch 195/200\n",
      "19/19 [==============================] - 13s 666ms/step - loss: 0.8271 - accuracy: 0.8200\n",
      "Epoch 196/200\n",
      "19/19 [==============================] - 13s 662ms/step - loss: 0.8294 - accuracy: 0.8300\n",
      "Epoch 197/200\n",
      "19/19 [==============================] - 12s 655ms/step - loss: 0.8241 - accuracy: 0.8317\n",
      "Epoch 198/200\n",
      "19/19 [==============================] - 12s 656ms/step - loss: 0.8276 - accuracy: 0.8200\n",
      "Epoch 199/200\n",
      "19/19 [==============================] - 12s 654ms/step - loss: 0.8247 - accuracy: 0.8233\n",
      "Epoch 200/200\n",
      "19/19 [==============================] - 13s 698ms/step - loss: 0.8213 - accuracy: 0.8183\n"
     ]
    }
   ],
   "source": [
    "## fit for 200 epochs and train\n",
    "\n",
    "history = model.fit(x_train,y_train,epochs = 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd72705b-f8ea-4903-ad0d-5fe6f451672f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0818 21:57:47.380365 140298920219008 deprecation.py:323] From <ipython-input-13-1e233bf338d4>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           precision    recall  f1-score   support\n",
      "\n",
      "driving license (Class 0)       0.82      0.86      0.84       200\n",
      "       pan card (Class 1)       0.89      0.84      0.86       200\n",
      "         Others (Class 2)       0.79      0.79      0.79       200\n",
      "\n",
      "                micro avg       0.83      0.83      0.83       600\n",
      "                macro avg       0.83      0.83      0.83       600\n",
      "             weighted avg       0.83      0.83      0.83       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# inference on xtrain,to see accuracy metrics\n",
    "predictions = model.predict_classes(x_train)\n",
    "predictions = predictions.reshape(1,-1)[0]\n",
    "print(classification_report(y_train, predictions, target_names = ['driving license (Class 0)','pan card (Class 1)','Others (Class 2)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d89aeabf-af6f-4e87-bd8e-0eb5eef8f59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_negative.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfd5980-85aa-4bd0-94b4-043f725a0807",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
